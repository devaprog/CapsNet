{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download DataSet: Ensure Completion of Uploading kaggle.json in colab before execution to get dataset from Kaggle."
      ],
      "metadata": {
        "id": "IGGm4Lh4I77p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! kaggle datasets download -d kmader/lungnodemalignancy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob2PPAIuJIqX",
        "outputId": "51d78056-8f84-441f-bd19-a9de2e01ca65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading lungnodemalignancy.zip to /content\n",
            "100% 94.9M/94.9M [00:06<00:00, 19.4MB/s]\n",
            "100% 94.9M/94.9M [00:06<00:00, 15.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip Dataset:"
      ],
      "metadata": {
        "id": "p7hsp8k4J0hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/lungnodemalignancy.zip')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "i8N4sa01J6i9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete Dataset Zip and Unwanted Files: It is not mandatory, Not good in case You Not Sure that the Dataset is fully Extracted"
      ],
      "metadata": {
        "id": "Eew3tgonKFuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r '/content/sample_data' '/content/lungnodemalignancy.zip' '/content/kaggle.json'"
      ],
      "metadata": {
        "id": "SZj0wDLXKbB-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Capsule Network (CapsNet) for image classification i.e, Detection of Lung Nodule Malignancy**"
      ],
      "metadata": {
        "id": "LteXlA4IKfIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Augmentation Module (data_augmentation.py):"
      ],
      "metadata": {
        "id": "rWKVAIniHB0P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ag-kIyJpULue"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def create_data_generator(width_shift_range=0., height_shift_range=0.):\n",
        "  \"\"\"\n",
        "  Creates an ImageDataGenerator for data augmentation.\n",
        "\n",
        "  Args:\n",
        "    width_shift_range: Fraction of total width for random horizontal shifts.\n",
        "    height_shift_range: Fraction of total height for random vertical shifts.\n",
        "\n",
        "  Returns:\n",
        "    An ImageDataGenerator object.\n",
        "  \"\"\"\n",
        "  train_datagen = ImageDataGenerator(width_shift_range=width_shift_range,\n",
        "                                    height_shift_range=height_shift_range)\n",
        "  return train_datagen\n",
        "\n",
        "def generate_data(x, y, batch_size):\n",
        "  \"\"\"\n",
        "  Generates batches of data with optional augmentation.\n",
        "\n",
        "  Args:\n",
        "    x: Input data.\n",
        "    y: Target labels.\n",
        "    batch_size: Batch size.\n",
        "\n",
        "  Yields:\n",
        "    A tuple of (x_batch, y_batch) for training.\n",
        "  \"\"\"\n",
        "  generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "  while 1:\n",
        "    x_batch, y_batch = generator.next()\n",
        "    yield ([x_batch, y_batch], [y_batch, x_batch])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data Loading Module (data_loading.py):"
      ],
      "metadata": {
        "id": "pt7B_x0LHHTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def load_data(data_path):\n",
        "  \"\"\"\n",
        "  Loads data from HDF5 files.\n",
        "\n",
        "  Args:\n",
        "    data_path: Path to the HDF5 file containing data.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of (X_full, y_full):\n",
        "      - X_full: Input data (numpy array).\n",
        "      - y_full: Target labels (numpy array).\n",
        "  \"\"\"\n",
        "  with h5py.File(data_path, 'r') as f:\n",
        "    X_full = f['ct_slices'][:]\n",
        "    y_full = f['slice_class'][:]\n",
        "\n",
        "  X_full = np.expand_dims(X_full[:, ::2, ::2], -1)  # downsample and add depth\n",
        "  X_full = np.clip((X_full + 600)/900, 0, 1).astype(np.float32)  # normalize\n",
        "  y_full = to_categorical(y_full.astype(np.float32))\n",
        "\n",
        "  return X_full, y_full\n",
        "\n",
        "def split_data(X_full, y_full, test_size=0.3):\n",
        "  \"\"\"\n",
        "  Splits data into training and testing sets.\n",
        "\n",
        "  Args:\n",
        "    X_full: Full input data.\n",
        "    y_full: Full target labels.\n",
        "    test_size: Fraction of data for the testing set.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of ((x_train, y_train), (x_test, y_test)):\n",
        "      - x_train: Training input data.\n",
        "      - y_train: Training target labels.\n",
        "      - x_test: Testing input data.\n",
        "      - y_test: Testing target labels.\n",
        "  \"\"\"\n",
        "  return train_test_split(X_full, y_full, test_size=test_size)\n"
      ],
      "metadata": {
        "id": "Zap9z96OHBLH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Model Creation Module (model_creation.py):"
      ],
      "metadata": {
        "id": "UNpqbKvmHYeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Conv2D, Reshape, Dense\n",
        "#from .custom_layers import Length, Mask, CapsuleLayer, PrimaryCap\n",
        "from keras import models\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "def create_capsnet(input_shape, n_class, num_routing):\n",
        "  \"\"\"\n",
        "  Creates a CapsNet model.\n",
        "\n",
        "  Args:\n",
        "    input_shape: Input data shape (tuple).\n",
        "    n_class: Number of classes.\n",
        "    num_routing: Number of routing iterations.\n",
        "\n",
        "  Returns:\n",
        "    A compiled Keras model.\n",
        "  \"\"\"\n",
        "  x = Input(shape=input_shape)\n",
        "\n",
        "  # Layer 1: Just a conventional Conv2D layer\n",
        "  conv1 = Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "  # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_vector]\n",
        "  primarycaps = PrimaryCap(conv1, dim_vector=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "  # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "  digitcaps = CapsuleLayer(num_capsule=n_class, dim_vector=16, num_routing=num_routing, name='digitcaps')(primarycaps)\n",
        "\n",
        "  # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "  # If using tensorflow, this will not be necessary. :)\n",
        "  out_caps = Length(name='out_caps')(digitcaps)\n",
        "\n",
        "  # Decoder network.\n",
        "  y = Input(shape=(n_class,))\n",
        "  masked = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer.\n",
        "  x_recon = Dense(512, activation='relu')(masked)\n",
        "  x_recon = Dense(1024, activation='relu')(x_recon)\n",
        "  x_recon = Dense(np.prod(input_shape).astype(int), activation='sigmoid')(x_recon)\n",
        "  x_recon = Reshape(target_shape=input_shape, name='out_recon')(x_recon)\n",
        "\n",
        "  # Two-input-two-output Keras Model\n",
        "  model = models.Model([x, y], [out_caps, x_recon])\n",
        "\n",
        "  return model\n",
        "\n",
        "  # ... rest of the function with the loss function (margin_loss) and compilation\n",
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))\n"
      ],
      "metadata": {
        "id": "yksjzPfhHa82"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Training Module (model_training.py):"
      ],
      "metadata": {
        "id": "YttxQX-hIKzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "def train_model(model, data, epoch_size_frac, epochs):\n",
        "  \"\"\"\n",
        "  Trains a CapsNet model.\n",
        "\n",
        "  Args:\n",
        "    model: The CapsNet model to train.\n",
        "    data: A tuple of ((x_train, y_train), (x_test, y_test)).\n",
        "    epoch_size_frac: Fraction of the training data to use per epoch.\n",
        "    epochs: Number of training epochs.\n",
        "\n",
        "  Returns:\n",
        "    The trained model.\n",
        "  \"\"\"\n",
        "  (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "  # Define callbacks\n",
        "  log = CSVLogger('log.csv')\n",
        "  checkpoint = ModelCheckpoint('weights-{epoch:02d}.h5',\n",
        "                               save_best_only=True, save_weights_only=True, verbose=1)\n",
        "  lr_decay = LearningRateScheduler(schedule=lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
        "\n",
        "  # Train the model\n",
        "  model.fit_generator(generator=generate_data(x_train, y_train, 64, 0.1),\n",
        "                      steps_per_epoch=int(epoch_size_frac*y_train.shape[0] / 64),\n",
        "                      epochs=epochs,\n",
        "                      validation_data=[[x_test, y_test], [y_test, x_test]],\n",
        "                      callbacks=[log, checkpoint, lr_decay])\n",
        "\n",
        "  model.save_weights('trained_model.h5')\n",
        "  print('Trained model saved to \\'trained_model.h5\\'')\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "80zztfOvILvw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Testing Module (testing.py):"
      ],
      "metadata": {
        "id": "yy25teRWIPhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from .data_augmentation import generate_data\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def test_model(model, data):\n",
        "  \"\"\"\n",
        "  Evaluates a CapsNet model on the testing data.\n",
        "\n",
        "  Args:\n",
        "    model: The trained CapsNet model.\n",
        "    data: A tuple of (x_test, y_test).\n",
        "\n",
        "  Prints the test accuracy and saves reconstructed images.\n",
        "  \"\"\"\n",
        "  x_test, y_test = data\n",
        "  y_pred, x_recon = model.predict([x_test, y_test], batch_size=100)\n",
        "\n",
        "  print('-'*50)\n",
        "  print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
        "\n",
        "  img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n",
        "  image = img * 255\n",
        "  Image.fromarray(image.astype(np.uint8)).save(\"real_and_recon.png\")\n",
        "  print()\n",
        "  print('Reconstructed images are saved to ./real_and_recon.png')\n",
        "  print('-'*50)\n",
        "\n",
        "  plt.imshow(plt.imread(\"real_and_recon.png\", ))\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "T6GMEvacISmR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Custom Layers Module (custom_layers.py):"
      ],
      "metadata": {
        "id": "BdTTqlGwIiiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import initializers, layers\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss\n",
        "    inputs: shape=[dim_1, ..., dim_{n-1}, dim_n]\n",
        "    output: shape=[dim_1, ..., dim_{n-1}]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, d1, d2] by the max value in axis=1.\n",
        "    Output shape: [None, d2]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        # use true label to select target capsule, shape=[batch_size, num_capsule]\n",
        "        if type(inputs) is list:  # true label is provided with shape = [batch_size, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of vectors of capsules\n",
        "            x = inputs\n",
        "            # Enlarge the range of values in x to make max(new_x)=1 and others < 0\n",
        "            x = (x - K.max(x, 1, True)) / K.epsilon() + 1\n",
        "            mask = K.clip(x, 0, 1)  # the max value in x clipped to 1 and other to 0\n",
        "\n",
        "        # masked inputs, shape = [batch_size, dim_vector]\n",
        "        inputs_masked = K.batch_dot(inputs, mask, [1, 1])\n",
        "        return inputs_masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][-1]])\n",
        "        else:\n",
        "            return tuple([None, input_shape[-1]])\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm)\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_vector] and output shape = \\\n",
        "    [None, num_capsule, dim_vector]. For Dense Layer, input_dim_vector = dim_vector = 1.\n",
        "\n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_vector: dimension of the output vectors of the capsules in this layer\n",
        "    :param num_routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_vector, num_routing=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_vector = dim_vector\n",
        "        self.num_routing = num_routing\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_vector]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_vector = input_shape[2]\n",
        "\n",
        "        # Transform matrix\n",
        "        self.W = self.add_weight(shape=[self.input_num_capsule, self.num_capsule, self.input_dim_vector, self.dim_vector],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        # Coupling coefficient. The redundant dimensions are just to facilitate subsequent matrix calculation.\n",
        "        self.bias = self.add_weight(shape=[1, self.input_num_capsule, self.num_capsule, 1, 1],\n",
        "                                    initializer=self.bias_initializer,\n",
        "                                    name='bias',\n",
        "                                    trainable=False)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_vector]\n",
        "        # Expand dims to [None, input_num_capsule, 1, 1, input_dim_vector]\n",
        "        inputs_expand = K.expand_dims(K.expand_dims(inputs, 2), 2)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # Now it has shape = [None, input_num_capsule, num_capsule, 1, input_dim_vector]\n",
        "        inputs_tiled = K.tile(inputs_expand, [1, 1, self.num_capsule, 1, 1])\n",
        "\n",
        "        \"\"\"\n",
        "        # Compute `inputs * W` by expanding the first dim of W. More time-consuming and need batch_size.\n",
        "        # Now W has shape  = [batch_size, input_num_capsule, num_capsule, input_dim_vector, dim_vector]\n",
        "        w_tiled = K.tile(K.expand_dims(self.W, 0), [self.batch_size, 1, 1, 1, 1])\n",
        "\n",
        "        # Transformed vectors, inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n",
        "        inputs_hat = K.batch_dot(inputs_tiled, w_tiled, [4, 3])\n",
        "        \"\"\"\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0. This is faster but requires Tensorflow.\n",
        "        # inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n",
        "        inputs_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]),\n",
        "                             elems=inputs_tiled,\n",
        "                             initializer=K.zeros([self.input_num_capsule, self.num_capsule, 1, self.dim_vector]))\n",
        "        \"\"\"\n",
        "        # Routing algorithm V1. Use tf.while_loop in a dynamic way.\n",
        "        def body(i, b, outputs):\n",
        "            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n",
        "            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n",
        "            b = b + K.sum(inputs_hat * outputs, -1, keepdims=True)\n",
        "            return [i-1, b, outputs]\n",
        "\n",
        "        cond = lambda i, b, inputs_hat: i > 0\n",
        "        loop_vars = [K.constant(self.num_routing), self.bias, K.sum(inputs_hat, 1, keepdims=True)]\n",
        "        _, _, outputs = tf.while_loop(cond, body, loop_vars)\n",
        "        \"\"\"\n",
        "        # Routing algorithm V2. Use iteration. V2 and V1 both work without much difference on performance\n",
        "        assert self.num_routing > 0, 'The num_routing should be > 0.'\n",
        "        for i in range(self.num_routing):\n",
        "            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n",
        "            # outputs.shape=[None, 1, num_capsule, 1, dim_vector]\n",
        "            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n",
        "\n",
        "            # last iteration needs not compute bias which will not be passed to the graph any more anyway.\n",
        "            if i != self.num_routing - 1:\n",
        "                # self.bias = K.update_add(self.bias, K.sum(inputs_hat * outputs, [0, -1], keepdims=True))\n",
        "                self.bias += K.sum(inputs_hat * outputs, -1, keepdims=True)\n",
        "            # tf.summary.histogram('BigBee', self.bias)  # for debugging\n",
        "        return K.reshape(outputs, [-1, self.num_capsule, self.dim_vector])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_vector])\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_vector, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_vector: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_vector]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_vector*n_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_vector])(output)\n",
        "    return layers.Lambda(squash)(outputs)\n",
        ""
      ],
      "metadata": {
        "id": "Ni1cbFoUIlno"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Script (main.py):"
      ],
      "metadata": {
        "id": "4gmheRU4IqF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data_path = '/content/all_patches.hdf5'\n",
        "X_full, y_full = load_data(data_path)\n",
        "\n",
        "# Split data\n",
        "x_train, x_test, y_train, y_test = split_data(X_full, y_full)\n",
        "\n",
        "# Define model parameters\n",
        "input_shape = [32, 32, 1]\n",
        "n_class = 2\n",
        "num_routing = 3\n",
        "\n",
        "# Create CapsNet model #create_capsnet\n",
        "model = create_capsnet(input_shape, n_class, num_routing)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "train_model(model, (x_train, y_train), epoch_size_frac=1.0, epochs=10)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "nAGTm7HgIpjq",
        "outputId": "a526341c-bdcb-4d3e-e758-e299b2d435a7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"digitcaps\" (type CapsuleLayer).\n\nin user code:\n\n    File \"<ipython-input-9-8b4cde22a264>\", line 114, in call  *\n        inputs_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]),\n\n    ValueError: Inconsistent shapes: saw (2048, 2, 1, 2, 16) but expected (2048, 2, 1, 16) \n\n\nCall arguments received by layer \"digitcaps\" (type CapsuleLayer):\n  • inputs=tf.Tensor(shape=(None, 2048, 8), dtype=float32)\n  • training=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-17e73c2a6647>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Create CapsNet model #create_capsnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_capsnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_routing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-c371c7dd60b1>\u001b[0m in \u001b[0;36mcreate_capsnet\u001b[0;34m(input_shape, n_class, num_routing)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# Layer 3: Capsule layer. Routing algorithm works here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0mdigitcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCapsuleLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_capsule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_vector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_routing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_routing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'digitcaps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimarycaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0;31m# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filervto94do.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0minputs_tiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_expand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_capsule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;34m'  \\n        # Compute `inputs * W` by expanding the first dim of W. More time-consuming and need batch_size.\\n        # Now W has shape  = [batch_size, input_num_capsule, num_capsule, input_dim_vector, dim_vector]\\n        w_tiled = K.tile(K.expand_dims(self.W, 0), [self.batch_size, 1, 1, 1, 1])\\n        \\n        # Transformed vectors, inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\\n        inputs_hat = K.batch_dot(inputs_tiled, w_tiled, [4, 3])\\n        '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0minputs_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_tiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_num_capsule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_capsule...\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;34m'\\n        # Routing algorithm V1. Use tf.while_loop in a dynamic way.\\n        def body(i, b, outputs):\\n            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\\n            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\\n            b = b + K.sum(inputs_hat * outputs, -1, keepdims=True)\\n            return [i-1, b, outputs]\\n\\n        cond = lambda i, b, inputs_hat: i > 0\\n        loop_vars = [K.constant(self.num_routing), self.bias, K.sum(inputs_hat, 1, keepdims=True)]\\n        _, _, outputs = tf.while_loop(cond, body, loop_vars)\\n        '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_routing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The num_routing should be > 0.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"digitcaps\" (type CapsuleLayer).\n\nin user code:\n\n    File \"<ipython-input-9-8b4cde22a264>\", line 114, in call  *\n        inputs_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]),\n\n    ValueError: Inconsistent shapes: saw (2048, 2, 1, 2, 16) but expected (2048, 2, 1, 16) \n\n\nCall arguments received by layer \"digitcaps\" (type CapsuleLayer):\n  • inputs=tf.Tensor(shape=(None, 2048, 8), dtype=float32)\n  • training=None"
          ]
        }
      ]
    }
  ]
}